---
title: "Analyse Tour de France Wikipedia articles"
output:
  html_document:
    df_print: paged
---

# SETUP
Load libraries
```{r setup}
library(tidyverse)
library(tidytext)
library(widyr)
library(igraph)
library(ggraph)
```

Load text data
```{r load}
text_raw <- read_csv("data/text_raw.csv")
```

Convert to tidytext format (one token, word in this case, per row)
```{r unnest_word}
tidy_word <- text_raw %>%
  filter(!is.na(text)) %>%
  unnest_tokens(word, text, token = "words")

tidy_word[1:10,]
```

Find frequency of words excluding stop words
```{r word_freq}
tidy_word <- tidy_word %>%
  anti_join(stop_words) 

tidy_word %>%
  count(word, sort = TRUE) %>%
  filter(n > 500) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

Assign each year to a decade to make it easier to compare sets of years.
```{r add_decade}
tidy_word <- tidy_word %>%
  mutate(decade = (year %/% 10) * 10)
```

Find words with the highest tf_idf for each decade.
```{r decade_tfidf}
text_decade <- tidy_word %>%
  group_by(decade) %>%
  count(word, sort = TRUE) %>%
  bind_tf_idf(word, decade, n) %>%
  ungroup()

text_decade %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  group_by(decade) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  labs(x = NULL, y = "tf_idf") +
  facet_wrap(~ decade, ncol = 3, scales = "free") +
  coord_flip()
```

Find words which occur together in the same article for a year more often than they occur in different years.
```{r pairwise_corr}
word_cors <- tidy_word %>%
  group_by(word) %>%
  filter(n() >= 15) %>%
  pairwise_cor(word, year, sort = TRUE)

word_cors 
```

Produce network diagram showing which words tend to occur together.
```{r network_graph}
word_cors %>%
  filter(correlation > 0.9) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(colour = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```

Create bigrams, and then draw graph of which bigrams occur most often with each other, can then see connections between teams or people, rather than just connecting first names with second names.
```{r bigrams}
tidy_bigram <- text_raw %>%
  filter(!is.na(text)) %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

tidy_bigram <- tidy_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!(word1 %in% stop_words$word)) %>%
  filter(!(word2 %in% stop_words$word)) %>%
  unite(bigram, c("word1", "word2"), sep = " ")

bigram_cors <- tidy_bigram %>%
  group_by(bigram) %>%
  filter(n() >= 10) %>%
  pairwise_cor(bigram, year, sort = TRUE)

bigram_cors[1:20,]

bigram_cors %>%
  filter(correlation > 0.95) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(colour = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()

bigram_cors %>%
  filter(item1 == "lance armstrong", correlation > 0.3) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(colour = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()

bigram_cors %>%
  filter(item1 == "km 1.9", correlation > 0.9) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(colour = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()

tidy_bigram %>%
  filter(bigram == "km 1.9")
```
